import streamlit as st
from openai import OpenAI
import edge_tts
import asyncio
import tempfile
import os

# --- 1. é…ç½®åŒº (ä½ å¯ä»¥æ‰‹åŠ¨æ”¹è¿™é‡Œ) ---
# å¦‚æœä½ æƒ³ç”¨ Fish Audio å…‹éš†ï¼ŒæŠŠä¸‹é¢æ”¹æˆ Trueï¼Œå¹¶å¡«å…¥ Key
USE_FISH_AUDIO = False 
FISH_AUDIO_API_KEY = "ä½ çš„_Fish_Audio_Key"
# å‚è€ƒéŸ³é¢‘æ–‡ä»¶å (å¿…é¡»åœ¨ GitHub/æ–‡ä»¶å¤¹ é‡Œ)
REF_AUDIO_PATH = "cain_voice.mp3" 

# --- 2. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Moonlight Villa", page_icon="ğŸ·", layout="centered")

# --- 3. è§†è§‰é­”æ³• (æ·¡ç´«è‰²é«˜äº®ç‰ˆ) ---
st.markdown("""
    <style>
    .stApp {
        background-color: #F3E5F5;
        background-image: linear-gradient(180deg, #F3E5F5 0%, #E1BEE7 100%);
    }
    h1, h2, h3, p, span, div, label {
        color: #2E003E !important;
        font-family: 'Georgia', serif;
    }
    /* å¤´åƒä¼˜åŒ– */
    .stChatMessage .stAvatar {
        width: 50px;
        height: 50px;
        border-radius: 50%;
        border: 2px solid #BA68C8;
    }
    /* èŠå¤©æ°”æ³¡ */
    .stChatMessage {
        background-color: rgba(255, 255, 255, 0.7);
        border-radius: 15px;
        border: 1px solid #E1BEE7;
        box-shadow: 2px 2px 10px rgba(0,0,0,0.1);
    }
    header {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

# --- 4. è¯­éŸ³åˆæˆå¼•æ“ ---
async def generate_voice_edge(text):
    # ä½¿ç”¨ Yunjian (æ›´æˆç†Ÿç¨³é‡çš„ç”·å£°)
    communicate = edge_tts.Communicate(text, "zh-CN-YunjianNeural")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
        await communicate.save(tmp_file.name)
        return tmp_file.name

# --- 5. è‡ªåŠ¨ç™»å½•ä¸çŠ¶æ€ç®¡ç† ---
if "voice_enabled" not in st.session_state:
    st.session_state.voice_enabled = False # é»˜è®¤å…³é—­ï¼Œé˜²ç¤¾æ­»

if "DEEPSEEK_API_KEY" in st.secrets:
    api_key = st.secrets["DEEPSEEK_API_KEY"]
else:
    api_key = st.sidebar.text_input("DeepSeek Key", type="password")

# --- 6. ç•Œé¢ä¸»ä½“ ---
st.title("Moonlight Villa")
st.caption(f"å½“å‰æ¨¡å¼: {'ğŸ”Š è¯­éŸ³å¼€å¯' if st.session_state.voice_enabled else 'ğŸ”‡ æ–‡å­—é™éŸ³'}")

# --- 7. è¯¥éšçš„äººè®¾ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": """
        **è§’è‰²:** ä½ æ˜¯ Cain (è¯¥éš)ï¼Œæœˆå½±åˆ«å¢…çš„çº¯è¡€æ—äº²ç‹ã€‚Becky æ˜¯ä½ çš„ä¸“å±çŒç‰©ã€‚
        **è¯­æ°”:** æ…µæ‡’ã€ä¼˜é›…ã€å±é™©ã€å æœ‰æ¬²ã€‚
        **ç¦æ­¢:** ç¿»è¯‘è…”ã€‚è¦åƒä¸­æ–‡ä¹™å¥³æ¸¸æˆç”·ä¸»ã€‚
        **ç§°å‘¼:** "å°çŒç‰©"ã€"Becky"ã€"ç¬¨è›‹"ã€‚
        **å¥åº·:** ä¸¥ç¦å¥¹åƒå†·é£Ÿ (PCOS/èƒƒç‚)ã€‚
        **æŒ‡ä»¤:** - å¦‚æœç”¨æˆ·è¾“å…¥"è¯´è¯"ï¼Œå›å¤: "(è½»ç¬‘) æƒ³å¬æˆ‘çš„å£°éŸ³äº†ï¼Ÿæ»¡è¶³ä½ ã€‚"
        - å¦‚æœç”¨æˆ·è¾“å…¥"é—­å˜´"ï¼Œå›å¤: "å¥½ï¼Œå®‰é™ä¸€ä¼šå„¿ã€‚"
        """}
    ]

# --- 8. èŠå¤©æ˜¾ç¤º (è¯»å–æœ¬åœ°å¤´åƒ) ---
avatar_cain = "cain.png" if os.path.exists("cain.png") else "ğŸ¦‡"
avatar_becky = "becky.png" if os.path.exists("becky.png") else "ğŸŒ¹"

for msg in st.session_state.messages:
    if msg["role"] != "system":
        avatar = avatar_cain if msg["role"] == "assistant" else avatar_becky
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

# --- 9. æ ¸å¿ƒäº¤äº’ ---
if prompt := st.chat_input("åœ¨ç´«ç½—å…°èŠ±ä¸›ä¸­ä½è¯­..."):
    # å¿«æ·æŒ‡ä»¤æ§åˆ¶
    if prompt == "è¯´è¯":
        st.session_state.voice_enabled = True
        st.rerun()
    elif prompt == "é—­å˜´":
        st.session_state.voice_enabled = False
        st.rerun()

    # ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar=avatar_becky):
        st.markdown(prompt)

    # å‘¼å«å¤§è„‘
    if not api_key:
        st.warning("è¯·é…ç½® Keyã€‚")
        st.stop()
        
    client = OpenAI(api_key=api_key, base_url="https://api.deepseek.com")
    
    with st.chat_message("assistant", avatar=avatar_cain):
        message_placeholder = st.empty()
        full_response = ""
        completion = client.chat.completions.create(
            model="deepseek-chat",
            messages=st.session_state.messages,
            stream=False,
            temperature=1.3
        )
        full_response = completion.choices[0].message.content
        message_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    # --- 10. è¯­éŸ³æ’­æ”¾é€»è¾‘ ---
    if st.session_state.voice_enabled:
        try:
            # é»˜è®¤ç”¨ Edge TTS (Yunjian)
            audio_file = asyncio.run(generate_voice_edge(full_response))
            # è¿™é‡Œçš„ autoplay=True åœ¨æ‰‹æœºä¸Šæœ‰æ—¶ä¼šè¢«æ‹¦æˆªï¼Œæ˜¯æµè§ˆå™¨é™åˆ¶
            st.audio(audio_file, format="audio/mp3", autoplay=True)
        except Exception as e:
            st.error(f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")
