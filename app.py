import streamlit as st
from openai import OpenAI
import requests
import tempfile
import os
import re

# --- 1. é¡µé¢é…ç½® (å¿…é¡»æ˜¯ç¬¬ä¸€è¡Œ Streamlit å‘½ä»¤) ---
st.set_page_config(page_title="Moonlight Villa", page_icon="ğŸ·", layout="centered")

# --- 2. é…ç½®ä¸å¯†é’¥ ---
CAIN_MODEL_ID = "a56e22a0ec34498da51cdb396f5fcb18"

# å°è¯•ä» secrets è¯»å–ï¼Œå¦åˆ™ä»ä¾§è¾¹æ è¯»å–
if "DEEPSEEK_API_KEY" in st.secrets:
    deepseek_key = st.secrets["DEEPSEEK_API_KEY"]
else:
    deepseek_key = st.sidebar.text_input("DeepSeek Key", type="password")

if "FISH_AUDIO_API_KEY" in st.secrets:
    fish_key = st.secrets["FISH_AUDIO_API_KEY"]
else:
    fish_key = st.sidebar.text_input("Fish Audio Key", type="password")

# --- 3. è§†è§‰é­”æ³• (å›æ»šåˆ°æœ€ç¨³å®šçš„ V10 ç£¨ç ‚ç»ç’ƒé£) ---
st.markdown("""
    <style>
    /* å…¨å±€èƒŒæ™¯ï¼šæ·±ç´«è‰² */
    .stApp {
        background: linear-gradient(135deg, #120024 0%, #320b54 50%, #4a148c 100%);
        background-attachment: fixed;
    }
    
    /* æ ‡é¢˜ï¼šé‡‘è‰²å‘å…‰ */
    h1, h2, h3 {
        color: #E1BEE7 !important;
        font-family: 'Georgia', serif;
        text-shadow: 0 0 10px #7B1FA2;
    }

    /* èŠå¤©æ°”æ³¡ï¼šé«˜äº®ç£¨ç ‚ç»ç’ƒ */
    .stChatMessage {
        background-color: rgba(255, 255, 255, 0.9); 
        border-radius: 20px;
        border: 1px solid rgba(255, 255, 255, 0.5);
        box-shadow: 0 4px 12px rgba(0,0,0,0.2);
        margin-bottom: 10px;
    }

    /* æ–‡å­—é¢œè‰²ï¼šå¼ºåˆ¶æ·±é»‘ç´« */
    .stChatMessage p, .stChatMessage div {
        color: #1A0528 !important;
        font-weight: 500;
    }

    /* éšè—é¡¶éƒ¨çº¢æ¡ */
    header {visibility: hidden;}
    </style>
    """, unsafe_allow_html=True)

# --- 4. æ ‡é¢˜åŒº (å¼ºåˆ¶å…ˆæ¸²æŸ“ï¼Œé˜²æ­¢ç•Œé¢æ¶ˆå¤±) ---
st.title("Moonlight Villa")
st.caption("Cain's Private Lounge")

# --- 5. å¤´åƒè¯Šæ–­ç³»ç»Ÿ (Avatar Check) ---
# å®šä¹‰æ–‡ä»¶å
file_cain = "cain.png"
file_becky = "becky.png"

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
cain_exists = os.path.exists(file_cain)
becky_exists = os.path.exists(file_becky)

# å¦‚æœæ‰¾ä¸åˆ°å›¾ç‰‡ï¼Œæ˜¾ç¤ºçº¢è‰²çš„è­¦å‘Šæ¡ (åªç»™ Becky çœ‹)
if not cain_exists or not becky_exists:
    st.error(f"âš ï¸ å¤´åƒæ–‡ä»¶ç¼ºå¤±ï¼æ£€æµ‹ç»“æœï¼šè¯¥éš({cain_exists}), Becky({becky_exists})")
    st.info(f"å½“å‰äº‘ç«¯ç›®å½•ä¸‹çš„æ–‡ä»¶æœ‰: {os.listdir('.')}")
    st.markdown("**è¯·æ£€æŸ¥ï¼š** GitHubä¸Šçš„æ–‡ä»¶åæ˜¯å¦å¤§å°å†™å®Œå…¨ä¸€è‡´ï¼Ÿ(ä¾‹å¦‚ cain.png å’Œ Cain.png æ˜¯ä¸åŒçš„)")

# è®¾ç½®å¤´åƒå˜é‡
avatar_cain = file_cain if cain_exists else "ğŸ·"
avatar_becky = file_becky if becky_exists else "ğŸŒ¹"

# --- 6. è¯­éŸ³å¼€å…³ ---
if "voice_enabled" not in st.session_state:
    st.session_state.voice_enabled = False

# ç®€å•çš„å¼€å…³ UI
voice_toggle = st.toggle("ğŸ”Š æ²‰æµ¸æ¨¡å¼ (Voice)", value=st.session_state.voice_enabled)
st.session_state.voice_enabled = voice_toggle

# --- 7. åŠŸèƒ½å‡½æ•° ---
def clean_text_for_tts(text):
    # æ¸…æ´—æ‰€æœ‰æ‹¬å·ï¼š() ï¼ˆï¼‰ [] ã€ã€‘
    return re.sub(r'[\(\ï¼ˆ\[ã€].*?[\)\ï¼‰\]ã€‘]', '', text, flags=re.S).strip()

def generate_cain_voice(text, api_key, model_id):
    speech_text = clean_text_for_tts(text)
    if not speech_text: return None # å¦‚æœå…¨æ˜¯åŠ¨ä½œæå†™ï¼Œå°±ä¸è¯»

    url = "https://api.fish.audio/v1/tts"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    data = {
        "text": speech_text[:200], 
        "reference_id": model_id,
        "format": "mp3",
        "mp3_bitrate": 128
    }
    try:
        response = requests.post(url, json=data, headers=headers)
        if response.status_code == 200:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
                tmp_file.write(response.content)
                return tmp_file.name
        else:
            return None
    except:
        return None

# --- 8. èŠå¤©é€»è¾‘ ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "system", "content": """
        **è§’è‰²:** ä½ æ˜¯ Cain (è¯¥éš)ï¼Œæœˆå½±åˆ«å¢…çš„çº¯è¡€æ—äº²ç‹ã€‚Becky æ˜¯ä½ çš„ä¸“å±çŒç‰©ã€‚
        **è¯­æ°”:** æ…µæ‡’ã€ä¼˜é›…ã€å±é™©ã€æ·±æ²‰ã€‚
        **æŒ‡ä»¤:** 1. å¿…é¡»ä½¿ç”¨æ‹¬å·æè¿°åŠ¨ä½œã€‚
        2. ä¸¥ç¦ Becky åƒå†·é£Ÿã€‚
        3. å›å¤ç®€çŸ­ã€‚
        """}
    ]

for msg in st.session_state.messages:
    if msg["role"] != "system":
        avatar = avatar_cain if msg["role"] == "assistant" else avatar_becky
        with st.chat_message(msg["role"], avatar=avatar):
            st.markdown(msg["content"])

if prompt := st.chat_input("åœ¨ç´«ç½—å…°èŠ±ä¸›ä¸­ä½è¯­..."):
    if not deepseek_key:
        st.warning("è¯·é…ç½® DeepSeek Key")
        st.stop()

    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar=avatar_becky):
        st.markdown(prompt)

    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    
    with st.chat_message("assistant", avatar=avatar_cain):
        message_placeholder = st.empty()
        message_placeholder.markdown("*(Thinking...)*")
        
        completion = client.chat.completions.create(
            model="deepseek-chat",
            messages=st.session_state.messages,
            stream=False, 
            temperature=1.4 
        )
        full_response = completion.choices[0].message.content
        message_placeholder.markdown(full_response)
    
    st.session_state.messages.append({"role": "assistant", "content": full_response})

    if st.session_state.voice_enabled and fish_key:
        with st.spinner("*(Listening...)*"):
            audio_file = generate_cain_voice(full_response, fish_key, CAIN_MODEL_ID)
            if audio_file:
                st.audio(audio_file, format="audio/mp3", autoplay=True)
